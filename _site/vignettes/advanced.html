<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Dmitriy Selivanov" />

<meta name="date" content="2016-08-22" />

<title>Advanced topics</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Advanced topics</h1>
<h4 class="author"><em>Dmitriy Selivanov</em></h4>
<h4 class="date"><em>2016-08-22</em></h4>



<p>This vignette demonstrates some advanced features of the text2vec package: how to read large collections of text stored on disk rather than in memory, and how to let text2vec functions use multiple cores.</p>
<div id="working-with-files" class="section level2">
<h2>Working with files</h2>
<p>In many cases, you will have a corpus of texts which are too large to fit in memory. This section demonstrates how to use <code>text2vec</code> to vectorize large collections of text stored in files.</p>
<p>Imagine that you want to build a topic model with <a href="http://cran.r-project.org/package=lda">lda</a> package, and that you have a collection of movie reviews stored in multiple text files on disk. For this vignette, we will create files on disk using the <code>movie_review</code> dataset:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(text2vec)
<span class="kw">library</span>(magrittr)
<span class="kw">data</span>(<span class="st">&quot;movie_review&quot;</span>)

<span class="co"># remove all internal EOL to simplify reading</span>
movie_review$review &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="dt">pattern =</span> <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>, <span class="dt">replacement =</span> <span class="st">' '</span>, 
                            <span class="dt">x =</span> movie_review$review, <span class="dt">fixed =</span> <span class="ot">TRUE</span>)
N_FILES &lt;-<span class="st"> </span><span class="dv">10</span>
CHUNK_LEN &lt;-<span class="st"> </span><span class="kw">nrow</span>(movie_review) /<span class="st"> </span>N_FILES
files &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span>:N_FILES, function(x) <span class="kw">tempfile</span>())
chunks &lt;-<span class="st"> </span><span class="kw">split</span>(movie_review, <span class="kw">rep</span>(<span class="dv">1</span>:N_FILES, 
                                  <span class="dt">each =</span> <span class="kw">nrow</span>(movie_review) /<span class="st"> </span>N_FILES ))
for (i in <span class="dv">1</span>:N_FILES ) {
  <span class="kw">write.table</span>(chunks[[i]], files[[i]], <span class="dt">quote =</span> T, <span class="dt">row.names =</span> F,
              <span class="dt">col.names =</span> T, <span class="dt">sep =</span> <span class="st">'|'</span>)
}

<span class="co"># Note what the moview review data looks like</span>
<span class="kw">str</span>(movie_review, <span class="dt">strict.width =</span> <span class="st">'cut'</span>)</code></pre></div>
<pre><code>## 'data.frame':    5000 obs. of  3 variables:
##  $ id       : chr  &quot;5814_8&quot; &quot;2381_9&quot; &quot;7759_3&quot; &quot;3630_4&quot; ...
##  $ sentiment: int  1 1 0 0 1 1 0 0 0 1 ...
##  $ review   : chr  &quot;With all this stuff going down at the moment with MJ&quot;..</code></pre>
<p>The <code>text2vec</code> provides functions to easily work with files. You need to follow a few steps.</p>
<ol style="list-style-type: decimal">
<li>Construct an iterator over the files with the <code>ifiles()</code> function.</li>
<li>Provide a function to <code>ifiles()</code> that can read those files. You can use a function from base R or any other package to read plain text, XML, or other files and convert them to text. The <code>text2vec</code> package doesn’t handle the reading itself.</li>
<li>Construct a tokens iterator from the files iterator using the <code>itoken()</code> function.</li>
</ol>
<p>Let’s see how it works:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(data.table)
reader &lt;-<span class="st"> </span>function(x, ...) {
  <span class="co"># read</span>
  chunk &lt;-<span class="st"> </span><span class="kw">fread</span>(x, <span class="dt">header =</span> T, <span class="dt">sep =</span> <span class="st">'|'</span>)
  <span class="co"># select column with review</span>
  res &lt;-<span class="st"> </span>chunk$review
  <span class="co"># assign ids to reviews</span>
  <span class="kw">names</span>(res) &lt;-<span class="st"> </span>chunk$id
  res
}
<span class="co"># create iterator over files</span>
it_files  &lt;-<span class="st"> </span><span class="kw">ifiles</span>(files, <span class="dt">reader_function =</span> reader)
<span class="co"># create iterator over tokens from files iterator</span>
it_tokens &lt;-<span class="st"> </span><span class="kw">itoken</span>(it_files, <span class="dt">preprocess_function =</span> tolower, 
                    <span class="dt">tokenizer =</span> word_tokenizer, <span class="dt">progessbar =</span> <span class="ot">FALSE</span>)

vocab &lt;-<span class="st"> </span><span class="kw">create_vocabulary</span>(it_tokens)</code></pre></div>
<p>Now are able to construct DTM in <code>lda_c</code> format (as required by <code>lda</code> package):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dtm &lt;-<span class="st"> </span><span class="kw">create_dtm</span>(it_tokens, <span class="dt">vectorizer =</span> <span class="kw">vocab_vectorizer</span>(vocab), <span class="dt">type =</span> <span class="st">'lda_c'</span>)
<span class="kw">str</span>(dtm, <span class="dt">list.len =</span> <span class="dv">5</span>)</code></pre></div>
<pre><code>## List of 5000
##  $ 5814_8  : int [1:2, 1:229] 8655 1 9093 1 9353 1 9355 1 10186 1 ...
##  $ 2381_9  : int [1:2, 1:108] 8673 1 10195 1 12207 2 13452 2 16055 1 ...
##  $ 7759_3  : int [1:2, 1:256] 8434 1 8607 1 9215 1 9355 1 9383 1 ...
##  $ 3630_4  : int [1:2, 1:218] 8803 1 8946 1 9574 1 9898 1 10600 1 ...
##  $ 9495_8  : int [1:2, 1:254] 8358 1 8673 1 8917 1 9319 1 9626 1 ...
##   [list output truncated]
##  - attr(*, &quot;class&quot;)= chr &quot;lda_c&quot;</code></pre>
<p>Note that the DTM has document ids. They are inherited from the document names we assigned in <code>reader</code> function. This is a convenient way to assign document IDs when working with files.</p>
<p>Now we can fit <code>LDA</code> model using <code>lda::lda.collapsed.gibbs.sampler()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lda)
<span class="co"># prior for topics</span>
alpha =<span class="st"> </span><span class="fl">0.1</span>
<span class="co"># prior for words</span>
eta =<span class="st"> </span><span class="fl">0.001</span>
<span class="co"># fit model with 30 topics, make 30 Gibbs sampling iterations</span>
lda_fit &lt;-<span class="st"> </span><span class="kw">lda.collapsed.gibbs.sampler</span>(<span class="dt">documents =</span> dtm, <span class="dt">K =</span> <span class="dv">30</span>, 
                                       <span class="dt">vocab =</span> vocab$vocab$terms, 
                                       <span class="dt">alpha =</span> alpha, 
                                       <span class="dt">eta =</span> eta,
                                       <span class="dt">num.iterations =</span> <span class="dv">30</span>, 
                                       <span class="dt">trace =</span> 2L)</code></pre></div>
</div>
<div id="using-multiple-cores" class="section level2">
<h2>Using multiple cores</h2>
<p>The functions <code>create_dtm()</code>, <code>create_tcm()</code>, and <code>create_vocabulary()</code> are able to take advantage of multicore machines. In contrast to GloVe fitting which uses low-level thread parallelism via <code>RcppParallel</code>, these functions use standard high-level R parallelizatin provided by the <code>foreach</code> package. They are flexible and can use diffrent parallel backends, such as <code>doParallel()</code> or <code>doRedis()</code>. But remember that such high-level parallelism might involve significant overhead.</p>
<p>The user must do two things manually to take advantage of a multicore machine:</p>
<ol style="list-style-type: decimal">
<li>Register a parallel backend.</li>
<li>Prepare splits of the input data in the form of a list of <code>itoken</code> iterators.</li>
</ol>
<p>Here is simple example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N_WORKERS &lt;-<span class="st"> </span><span class="dv">4</span>
<span class="kw">library</span>(doParallel)
<span class="co"># register parallel backend</span>
<span class="kw">registerDoParallel</span>(N_WORKERS)

<span class="co">#  prepare splits</span>
<span class="co"># &quot;jobs&quot; is a list of itoken iterators!</span>
N_SPLITS &lt;-<span class="st"> </span><span class="dv">4</span>

jobs &lt;-<span class="st"> </span>files %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">split_into</span>(N_SPLITS) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">lapply</span>(ifiles, <span class="dt">reader_function =</span> reader) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="co"># Worth to set chunks_number to 1 because we already splitted input</span>
<span class="st">  </span><span class="kw">lapply</span>(itoken, <span class="dt">chunks_number =</span> <span class="dv">1</span>, <span class="dt">preprocess_function =</span> tolower, 
         <span class="dt">tokenizer =</span> word_tokenizer, <span class="dt">progessbar =</span> <span class="ot">FALSE</span>)

<span class="co"># Alternatively when data is in memory we can perform splite in the following way:</span>
<span class="co">#</span>
<span class="co"># review_chunks &lt;- split_into(movie_review$review, N_SPLITS)</span>
<span class="co"># review_ids &lt;- split_into(movie_review$id, N_SPLITS)</span>
<span class="co">#</span>
<span class="co"># jobs &lt;- Map(function(doc, ids) {</span>
<span class="co">#  itoken(iterable = doc, ids = ids, preprocess_function = tolower, </span>
<span class="co">#         tokenizer = word_tokenizer, chunks_number = 1, progessbar = FALSE) </span>
<span class="co"># }, review_chunks, review_ids)</span>

<span class="co"># Now all below function calls will benefit from multicore machines</span>
<span class="co"># Each job will be evaluated in separate process</span>

<span class="co"># vocabulary creation</span>
vocab &lt;-<span class="st"> </span><span class="kw">create_vocabulary</span>(jobs)

<span class="co"># DTM vocabulary vectorization</span>
v_vectorizer &lt;-<span class="st"> </span><span class="kw">vocab_vectorizer</span>(vocab)
vocab_dtm_parallel &lt;-<span class="st"> </span><span class="kw">create_dtm</span>(jobs, <span class="dt">vectorizer =</span> v_vectorizer)

<span class="co"># DTM hash vectorization</span>
h_vectorizer &lt;-<span class="st"> </span><span class="kw">hash_vectorizer</span>()
hash_dtm_parallel &lt;-<span class="st"> </span><span class="kw">create_dtm</span>(jobs, <span class="dt">vectorizer =</span> h_vectorizer)

<span class="co"># co-ocurence statistics</span>
tcm_vectorizer &lt;-<span class="st"> </span><span class="kw">vocab_vectorizer</span>(vocab, <span class="dt">grow_dtm =</span> <span class="ot">FALSE</span>, <span class="dt">skip_grams_window =</span> <span class="dv">5</span>)
tcm_parallel &lt;-<span class="st"> </span><span class="kw">create_tcm</span>(jobs, <span class="dt">vectorizer =</span> tcm_vectorizer)</code></pre></div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
