% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model_gibbs_LDA.R
\docType{data}
\name{LatentDirichletAllocation}
\alias{LatentDirichletAllocation}
\title{Creates Latent Dirichlet Allocation model.}
\format{An object of class \code{R6ClassGenerator} of length 24.}
\usage{
LatentDirichletAllocation
}
\arguments{
\item{n_topics}{desired number of topics. Also knows as \bold{K}.}

\item{vocabulary}{vocabulary in a form of \code{character} vector or class of
\code{text2vec_vocab}}

\item{doc_topic_prior}{prior for document-topic multinomial distribution.
Also knows as \bold{alpha}.}

\item{topic_word_prior}{prior for topic-word multinomial distribution.
Also knows as \bold{eta}.}

\item{...}{arguments passed to other methods (not used at the moment).}
}
\description{
\bold{Iterative algorithm}. Model can be fitted
via Collapsed Gibbs Sampling algorithm using \code{fit} or \code{fit_transf} methods.
}
\examples{
library(text2vec)
data("movie_review")
N = 500
tokens = movie_review$review[1:N] \%>\% tolower \%>\% word_tokenizer
it = itoken(tokens, ids = movie_review$id[1:N])
v = create_vocabulary(it) \%>\%
  prune_vocabulary(term_count_min = 5, doc_proportion_max = 0.2)
dtm = create_dtm(it, vocab_vectorizer(v), 'lda_c')
lda_model = LatentDirichletAllocation$new(n_topics = 10, vocabulary = v,
 doc_topic_prior = 0.1,
 topic_word_prior = 0.1,
 verbose = T)
 doc_topic_distr = lda_model$fit_transf(dtm, n_iter = 100, check_convergence_every_n = 20)
}
\keyword{datasets}

