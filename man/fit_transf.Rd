% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model_GloVe.R, R/model_LSA.R, R/model_gibbs_LDA.R, R/models_interface.R
\name{fit_transf.GloVe}
\alias{fit_transf}
\alias{fit_transf.GloVe}
\alias{fit_transf.LDA_gibbs}
\alias{fit_transf.LSA}
\title{Fit model to data, then transforms input}
\usage{
\method{fit_transf}{GloVe}(object, X, n_iter, convergence_tol = -1,
  verbose = interactive(), dump_every_n = 0L, ...)

\method{fit_transf}{LSA}(object, X, ...)

\method{fit_transf}{LDA_gibbs}(object, X, n_iter, convergence_tol = -1,
  check_convergence_every_n = 0, ...)

fit_transf(object, X, ...)
}
\arguments{
\item{object}{instance of class \code{text2vec_model}. See \link{LSA}.}

\item{X}{matrix like object. At the moment usually one of
\code{c("matrix", "dgCMatrix", "dgTMatrix", "lda_c")}}

\item{n_iter}{number of iterations}

\item{convergence_tol}{convergence tolerance}

\item{verbose}{verbose}

\item{dump_every_n}{dump model every n iterations}

\item{...}{arguments to underlying functions. Currently not used.}

\item{check_convergence_every_n}{\code{integer} specify schedule for cost fucntion caclculation.
For exaple, during LDA fitting calculation of perplexity can take noticable amount
of time. So it make sense to do not calculate it at each iteration.}
}
\value{
Transformed version of \code{X}
}
\description{
This is generic function to fit text2vec models (class = "text2vec_model")
and then apply fitted object to input.
Note, that this function modifies input model during fitting! See example below.
}
\examples{
data("movie_review")
N = 100
tokens = movie_review$review[1:N] \%>\% tolower \%>\% word_tokenizer
dtm = create_dtm(itoken(tokens), hash_vectorizer())
n_factors = 10
model = LSA(n_factors)
# model is closure! and it is mutable!
documents_latent_factors =  fit_transf(model, dtm)
documents_latent_factors_2 =  transf(model, dtm)
all.equal(documents_latent_factors, documents_latent_factors_2)
}

